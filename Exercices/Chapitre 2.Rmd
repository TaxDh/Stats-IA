---
title: "Exercices Chapitre 2"
output: pdf_document
date: "2024-01-31"
---
# Exercice 1
Pour chacune des parties (a) à (d), indiquez si nous s'attendre à ce que les performances d'une méthode d'apprentissage statistique flexible soient meilleur ou pire qu'une méthode rigide. Justifiez votre réponse.

## (a)
La taille de l'échantillon n est extrêmement grande et le nombre de prédicteurs p est petit.

Réponse:
*better - a more flexible approach will fit the data closer and with the*
*large sample size a better fit than an inflexible approach would be obtained*

## (b)
The number of predictors p is extremely large, and the number of observations n is small.

Réponse:
la meilleure méthode sera la rigide
*a flexible method would overfit the small number of observations*

## (c)
The relationship between the predictors and response is highly
non-linear.

Réponse:
Flexible, car si elle est hautement non linéaire, la méthode flexible pourra plus facilement attrapé cette non linéarité.
*better - with more degrees of freedom, a flexible model would obtain a*
*better fit*

## (d)
The variance of the error terms, i.e. \sigma^2 = Var(\epsilon), is extremely high.

Réponse:
*worse - flexible methods fit to the noise in the error terms and increase variance*

# 2

Explain whether each scenario is a classification or regression problem,
and indicate whether we are most interested in inference or prediction.
Finally, provide n and p.

## (a)
We collect a set of data on the top 500 firms in the US. For each
firm we record profit, number of employees, industry and the
CEO salary. We are interested in understanding which factors
affect CEO salary.

réponse:
De ce que je comprends, c'est qu'on veut faire de l'inférence statistique. Ici ils disent régression, je suis d'accord. n = 500 et p = 3
Solution:
*regression. inference. quantitative output of CEO salary based on CEO*
*firm's features.*
*n - 500 firms in the US*
*p - profit, number of employees, industry*

## (b)

We are considering launching a new product and wish to know
whether it will be a success or a failure. We collect data on 20
similar products that were previously launched. For each product
we have recorded whether it was a success or failure, price
charged for the product, marketing budget, competition price,
and ten other variables.

Réponse:
Classification

Solution:
classification. prediction. predicting new product's success or failure.
n - 20 similar products previously launched
p - price charged, marketing budget, comp. price, ten other variables

## (c)

We are interested in predicting the % change in the USD/Euro
exchange rate in relation to the weekly changes in the world
stock markets. Hence we collect weekly data for all of 2012. For
each week we record the % change in the USD/Euro, the %
change in the US market, the % change in the British market,
and the % change in the German market.

Réponse: On veut prédire, vu que ce sont des variables continues, régression.

Solution:
regression. prediction. quantitative output of % change
n - 52 weeks of 2012 weekly data
p - % change in US market, % change in British market, % change in German market

# 8
## (a)
Use the read.csv() function to read the data into R. Call the
loaded data college. Make sure that you have the directory set
to the correct location for the data.

Donc On lit les données:
```{r}
college <- read.csv(file = "College.csv", header = TRUE)
college
```

## b
On regarde les données avec la fonction view()
```{r}
View(college)
```

La première colonne est le nom des université. Essayons le code suivants:
```{r}
rownames(college) <- college[,1]
View(college)
```
la commande rownmaes(college) <- college[,1] a ajouté une colone de row.names. Le but et d'ajouter une colonne que r n'utilisera jamais pour faire des calculs. Maintenant on veut éliminer la colonne X: "le nom des université" vu qu'elle est en trop.
```{r}
college <- college[,-1]
View(college)
```

## (C)
### (i)
```{r}
summary(college)
```

### (ii)
```{r}

pairs(college[, 1:10], cex = 0.2)
```


Solution:















































































